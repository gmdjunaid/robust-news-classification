{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Robust News Classification: Main Experiments\n",
        "\n",
        "This notebook ties together all components of the robust news classification project for the current flow (train on full ISOT, test on held-out files).\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. **Data Loading & Preprocessing**: Load ISOT training data and clean text\n",
        "2. **Training**: Train on the full ISOT training set (Fake + True)\n",
        "3. **Baseline Models**: TF-IDF + LogReg/SVM\n",
        "4. **Advanced Models**: Sentence embeddings (MiniLM)\n",
        "5. **Evaluation**:\n",
        "   - Fake-only test (`data/test/fake.csv`): false negatives / fake recall\n",
        "   - Mixed labeled test (`data/test/WELFake_Dataset_sample_10000.csv`): Macro-F1, ROC-AUC, PR-AUC, confusion matrix\n",
        "6. **Cross-Dataset Transfer**: WELFake evaluation covers the external test without fine-tuning\n",
        "\n",
        "## Project Goals\n",
        "\n",
        "- Train on full labeled ISOT data (text only)\n",
        "- Check false negatives on fake-only held-out data\n",
        "- Measure balanced metrics on a mixed external set (WELFake)\n",
        "- Compare TF-IDF baselines with embedding models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "Import all necessary modules from the `src/` directory and configure settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda: False\n",
            "mps: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print('cuda:', torch.cuda.is_available())\n",
        "print('mps:', torch.backends.mps.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize result holders to avoid NameError if optional cells are skipped\n",
        "# Base (text-only) variants\n",
        "results_lr_welfake = None\n",
        "results_svm_welfake = None\n",
        "results_emb_welfake = None\n",
        "fake_only_lr = None\n",
        "fake_only_svm = None\n",
        "fake_only_emb = None\n",
        "\n",
        "# Multi-feature / embedding+length variants\n",
        "results_lr_welfake_multi = None\n",
        "results_svm_welfake_multi = None\n",
        "results_emb_welfake_multi = None\n",
        "fake_only_lr_multi = None\n",
        "fake_only_svm_multi = None\n",
        "fake_only_emb_multi = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n",
            "Project root: /Users/reuben/robust-news-classification/robust-news-classification\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src directory to path for imports\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root / 'src'))\n",
        "\n",
        "# Import using importlib for files with numeric prefixes\n",
        "import importlib.util\n",
        "\n",
        "# Import preprocessing utilities\n",
        "spec = importlib.util.spec_from_file_location(\"preprocessing\", project_root / \"src\" / \"01_preprocessing.py\")\n",
        "preprocessing = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(preprocessing)\n",
        "sys.modules[\"preprocessing\"] = preprocessing\n",
        "from preprocessing import load_isot, apply_cleaning, clean_text\n",
        "\n",
        "# Import baseline models\n",
        "spec = importlib.util.spec_from_file_location(\"baseline_models\", project_root / \"src\" / \"03_baseline_models.py\")\n",
        "baseline_models = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(baseline_models)\n",
        "sys.modules[\"baseline_models\"] = baseline_models\n",
        "from baseline_models import build_tfidf, train_logreg, train_svm\n",
        "\n",
        "# Import evaluation\n",
        "spec = importlib.util.spec_from_file_location(\"baseline_eval\", project_root / \"src\" / \"04_baseline_eval.py\")\n",
        "baseline_eval = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(baseline_eval)\n",
        "sys.modules[\"baseline_eval\"] = baseline_eval\n",
        "from baseline_eval import evaluate\n",
        "\n",
        "print(\"All imports successful!\")\n",
        "print(f\"Project root: {project_root}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing\n",
        "\n",
        "Load the ISOT dataset (Fake and True news) and apply text cleaning to remove noise and standardize formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ISOT dataset...\n",
            "Loading fake news from ../data/training/Fake.csv...\n",
            "Loading real news from ../data/training/True.csv...\n",
            "Loaded 23481 fake articles and 21417 real articles\n",
            "Total: 44898 articles\n",
            "\n",
            "Dataset shape: (44898, 6)\n",
            "Columns: ['title', 'text', 'subject', 'date', 'label', 'source_file']\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "1    23481\n",
            "0    21417\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Subject distribution:\n",
            "subject\n",
            "politicsNews       11272\n",
            "worldnews          10145\n",
            "News                9050\n",
            "politics            6841\n",
            "left-news           4459\n",
            "Government News     1570\n",
            "US_News              783\n",
            "Middle-east          778\n",
            "Name: count, dtype: int64\n",
            "\n",
            "============================================================\n",
            "Applying text cleaning...\n",
            "Applied text cleaning to column 'text'\n",
            "Created new column 'text_cleaned' with cleaned text\n",
            "Applied text cleaning to column 'title'\n",
            "Created new column 'title_cleaned' with cleaned text\n",
            "\n",
            "Sample cleaned text (first 200 chars):\n",
            "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and the very dishonest fake news media. The former reali\n"
          ]
        }
      ],
      "source": [
        "# Load ISOT dataset\n",
        "print(\"Loading ISOT dataset...\")\n",
        "df = load_isot(\n",
        "    fake_path='../data/training/Fake.csv',\n",
        "    real_path='../data/training/True.csv'\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "print(f\"\\nSubject distribution:\")\n",
        "print(df['subject'].value_counts())\n",
        "\n",
        "# Apply text cleaning\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Applying text cleaning...\")\n",
        "df = apply_cleaning(df, text_column='text')\n",
        "df = apply_cleaning(df, text_column='title')\n",
        "\n",
        "print(f\"\\nSample cleaned text (first 200 chars):\")\n",
        "print(df['text_cleaned'].iloc[0][:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train/Test Setup\n",
        "\n",
        "Train on the full ISOT training set (Fake + True). Evaluate on two held-out files:\n",
        "- `data/test/fake.csv` (all fake) to measure false negatives (fake recall)\n",
        "- `data/test/WELFake_Dataset_sample_10000.csv` (mixed, labeled) for full metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Preparing train and held-out test sets\n",
            "============================================================\n",
            "\n",
            "Loading fake-only test set (all fake)...\n",
            "\n",
            "Loading WELFake test set (mixed labeled)...\n",
            "Train size: 44898\n",
            "Fake-only test size: 12999\n",
            "WELFake test size: 10000\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Preparing train and held-out test sets\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Train on full ISOT training set\n",
        "X_train_full = df['text_cleaned'].tolist()\n",
        "y_train_full = df['label'].values\n",
        "\n",
        "# Fake-only test set: measure false negatives / fake recall\n",
        "print(\"\\nLoading fake-only test set (all fake)...\")\n",
        "df_fake_test = pd.read_csv('../data/test/fake.csv')\n",
        "df_fake_test['text_cleaned'] = df_fake_test['text'].apply(clean_text)\n",
        "X_test_fake = df_fake_test['text_cleaned'].tolist()\n",
        "# Fake class = 1 (original convention)\n",
        "y_test_fake = np.ones(len(df_fake_test), dtype=int)\n",
        "\n",
        "# WELFake mixed test set: full metrics\n",
        "print(\"\\nLoading WELFake test set (mixed labeled)...\")\n",
        "df_welfake = pd.read_csv('../data/test/WELFake_Dataset_sample_10000.csv')\n",
        "# WELFake labels are actually 0=real, 1=fake; this matches our convention, so no mapping needed\n",
        "# If you find labels are reversed, flip with {0:1, 1:0}\n",
        "df_welfake['text_cleaned'] = df_welfake['text'].apply(clean_text)\n",
        "X_test_welfake = df_welfake['text_cleaned'].tolist()\n",
        "y_test_welfake = df_welfake['label'].values\n",
        "\n",
        "print(f\"Train size: {len(X_train_full)}\")\n",
        "print(f\"Fake-only test size: {len(X_test_fake)}\")\n",
        "print(f\"WELFake test size: {len(X_test_welfake)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Baseline Models: TF-IDF + Linear Classifiers\n",
        "\n",
        "Train interpretable baseline models using TF-IDF features with Logistic Regression and Linear SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "BASELINE MODELS: TF-IDF + Linear Classifiers\n",
            "============================================================\n",
            "Created TF-IDF vectorizer with:\n",
            "  max_features: 5000\n",
            "  min_df: 2\n",
            "  max_df: 0.95\n",
            "  ngram_range: (1, 2)\n",
            "  stop_words: english\n",
            "\n",
            "TF-IDF feature matrix shape: (44898, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Build TF-IDF vectorizer\n",
        "print(\"=\"*60)\n",
        "print(\"BASELINE MODELS: TF-IDF + Linear Classifiers\")\n",
        "print(\"=\"*60)\n",
        "vectorizer = build_tfidf(max_features=5000, ngram_range=(1, 2))\n",
        "\n",
        "# Transform text data (fit once on full training set)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_full)\n",
        "X_test_fake_tfidf = vectorizer.transform(X_test_fake)\n",
        "X_test_welfake_tfidf = vectorizer.transform(X_test_welfake)\n",
        "\n",
        "print(f\"\\nTF-IDF feature matrix shape: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Logistic Regression - Full Train -> WELFake\n",
            "============================================================\n",
            "Training Logistic Regression classifier...\n",
            "  Training samples: 44898\n",
            "  C (regularization): 1.0\n",
            "  max_iter: 1000\n",
            "  solver: lbfgs\n",
            "Training completed.\n",
            "  Training accuracy: 0.9925\n",
            "\n",
            "============================================================\n",
            "Evaluating Logistic Regression (WELFake)\n",
            "============================================================\n",
            "Test set size: 10000 samples\n",
            "Class distribution: {np.int64(0): np.int64(4844), np.int64(1): np.int64(5156)}\n",
            "\n",
            "Metrics                   Value          \n",
            "----------------------------------------\n",
            "Accuracy                  0.8358\n",
            "Precision (macro)         0.8656\n",
            "Recall (macro)            0.8313\n",
            "F1-score (macro)          0.8309  <-- PRIMARY METRIC\n",
            "F1-score (weighted)       0.8318\n",
            "ROC-AUC                   0.9048  <-- Secondary metric\n",
            "PR-AUC (Avg Precision)    0.8781  <-- Secondary metric\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted Real  Predicted Fake \n",
            "Actual Real     3332            1512           \n",
            "Actual Fake     130             5026           \n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.96      0.69      0.80      4844\n",
            "        Fake       0.77      0.97      0.86      5156\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.87      0.83      0.83     10000\n",
            "weighted avg       0.86      0.84      0.83     10000\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate Logistic Regression on full train -> WELFake\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Logistic Regression - Full Train -> WELFake\")\n",
        "print(\"=\"*60)\n",
        "model_lr = train_logreg(X_train_tfidf, y_train_full)\n",
        "results_lr_welfake = evaluate(model_lr, X_test_welfake_tfidf, y_test_welfake, \n",
        "                             model_name=\"Logistic Regression (WELFake)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Linear SVM - Full Train -> WELFake\n",
            "============================================================\n",
            "Training Linear SVM classifier...\n",
            "  Training samples: 44898\n",
            "  C (regularization): 1.0\n",
            "  max_iter: 1000\n",
            "  dual: False\n",
            "Training completed.\n",
            "  Training accuracy: 0.9990\n",
            "\n",
            "============================================================\n",
            "Evaluating Linear SVM (WELFake)\n",
            "============================================================\n",
            "Test set size: 10000 samples\n",
            "Class distribution: {np.int64(0): np.int64(4844), np.int64(1): np.int64(5156)}\n",
            "\n",
            "Metrics                   Value          \n",
            "----------------------------------------\n",
            "Accuracy                  0.8343\n",
            "Precision (macro)         0.8688\n",
            "Recall (macro)            0.8295\n",
            "F1-score (macro)          0.8288  <-- PRIMARY METRIC\n",
            "F1-score (weighted)       0.8297\n",
            "ROC-AUC                   0.9033  <-- Secondary metric\n",
            "PR-AUC (Avg Precision)    0.8803  <-- Secondary metric\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted Real  Predicted Fake \n",
            "Actual Real     3274            1570           \n",
            "Actual Fake     87              5069           \n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.97      0.68      0.80      4844\n",
            "        Fake       0.76      0.98      0.86      5156\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.87      0.83      0.83     10000\n",
            "weighted avg       0.87      0.83      0.83     10000\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate Linear SVM on full train -> WELFake\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Linear SVM - Full Train -> WELFake\")\n",
        "print(\"=\"*60)\n",
        "model_svm = train_svm(X_train_tfidf, y_train_full)\n",
        "results_svm_welfake = evaluate(model_svm, X_test_welfake_tfidf, y_test_welfake,\n",
        "                              model_name=\"Linear SVM (WELFake)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Fake-only test set (all fake) - TF-IDF models\n",
            "============================================================\n",
            "LogReg (fake-only): total=12999, false_negatives=826, fake_recall=0.9365\n",
            "Linear SVM (fake-only): total=12999, false_negatives=685, fake_recall=0.9473\n"
          ]
        }
      ],
      "source": [
        "# Fake-only test: false negatives / fake recall (TF-IDF models)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Fake-only test set (all fake) - TF-IDF models\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def fake_only_report(model, X_fake, model_name):\n",
        "    preds = model.predict(X_fake)\n",
        "    total = len(preds)\n",
        "    # Fake class = 1; false negatives are predictions of 0 (real)\n",
        "    fn = np.sum(preds == 0)\n",
        "    recall_fake = 1 - fn / total if total else float('nan')\n",
        "    print(f\"{model_name}: total={total}, false_negatives={fn}, fake_recall={recall_fake:.4f}\")\n",
        "    return {\"total\": int(total), \"false_negatives\": int(fn), \"fake_recall\": float(recall_fake)}\n",
        "\n",
        "fake_only_lr = fake_only_report(model_lr, X_test_fake_tfidf, \"LogReg (fake-only)\")\n",
        "fake_only_svm = fake_only_report(model_svm, X_test_fake_tfidf, \"Linear SVM (fake-only)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4b. Multi-feature TF-IDF + Length Features\n",
        "\n",
        "We augment the text-only baseline with title text (when available) and simple length features (text/title character counts) to see if multiple features improve performance. Models are trained on the concatenated title+body plus the length features and evaluated on the same test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MULTI-FEATURE MODELS: TF-IDF (title + text) + length features\n",
            "============================================================\n",
            "Created TF-IDF vectorizer with:\n",
            "  max_features: 7000\n",
            "  min_df: 2\n",
            "  max_df: 0.95\n",
            "  ngram_range: (1, 2)\n",
            "  stop_words: english\n",
            "\n",
            "============================================================\n",
            "Logistic Regression - Multi-feature (title+text+lengths) -> WELFake\n",
            "============================================================\n",
            "Training Logistic Regression classifier...\n",
            "  Training samples: 44898\n",
            "  C (regularization): 1.0\n",
            "  max_iter: 1000\n",
            "  solver: lbfgs\n",
            "Training completed.\n",
            "  Training accuracy: 0.9927\n",
            "\n",
            "============================================================\n",
            "Evaluating LogReg (multi-feature)\n",
            "============================================================\n",
            "Test set size: 10000 samples\n",
            "Class distribution: {np.int64(0): np.int64(4844), np.int64(1): np.int64(5156)}\n",
            "\n",
            "Metrics                   Value          \n",
            "----------------------------------------\n",
            "Accuracy                  0.8109\n",
            "Precision (macro)         0.8196\n",
            "Recall (macro)            0.8082\n",
            "F1-score (macro)          0.8085  <-- PRIMARY METRIC\n",
            "F1-score (weighted)       0.8092\n",
            "ROC-AUC                   0.8997  <-- Secondary metric\n",
            "PR-AUC (Avg Precision)    0.8972  <-- Secondary metric\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted Real  Predicted Fake \n",
            "Actual Real     3499            1345           \n",
            "Actual Fake     546             4610           \n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.87      0.72      0.79      4844\n",
            "        Fake       0.77      0.89      0.83      5156\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.81      0.81     10000\n",
            "\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "Linear SVM - Multi-feature (title+text+lengths) -> WELFake\n",
            "============================================================\n",
            "Training Linear SVM classifier...\n",
            "  Training samples: 44898\n",
            "  C (regularization): 1.0\n",
            "  max_iter: 1000\n",
            "  dual: False\n",
            "Training completed.\n",
            "  Training accuracy: 0.9994\n",
            "\n",
            "============================================================\n",
            "Evaluating Linear SVM (multi-feature)\n",
            "============================================================\n",
            "Test set size: 10000 samples\n",
            "Class distribution: {np.int64(0): np.int64(4844), np.int64(1): np.int64(5156)}\n",
            "\n",
            "Metrics                   Value          \n",
            "----------------------------------------\n",
            "Accuracy                  0.8233\n",
            "Precision (macro)         0.8432\n",
            "Recall (macro)            0.8195\n",
            "F1-score (macro)          0.8193  <-- PRIMARY METRIC\n",
            "F1-score (weighted)       0.8202\n",
            "ROC-AUC                   0.9142  <-- Secondary metric\n",
            "PR-AUC (Avg Precision)    0.9095  <-- Secondary metric\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted Real  Predicted Fake \n",
            "Actual Real     3377            1467           \n",
            "Actual Fake     300             4856           \n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.92      0.70      0.79      4844\n",
            "        Fake       0.77      0.94      0.85      5156\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.84      0.82      0.82     10000\n",
            "weighted avg       0.84      0.82      0.82     10000\n",
            "\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "Fake-only test set (all fake) - Multi-feature models\n",
            "============================================================\n",
            "LogReg (multi-feature, fake-only): total=12999, false_negatives=3580, fake_recall=0.7246\n",
            "Linear SVM (multi-feature, fake-only): total=12999, false_negatives=2143, fake_recall=0.8351\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"MULTI-FEATURE MODELS: TF-IDF (title + text) + length features\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Helper to build concatenated text and length features\n",
        "\n",
        "def build_concat_and_lengths(df, text_col=\"text_cleaned\", title_col=\"title_cleaned\"):\n",
        "    # Title may be missing (e.g., fake-only test). Fall back to empty strings.\n",
        "    if title_col in df.columns:\n",
        "        titles = df[title_col].fillna(\"\")\n",
        "    else:\n",
        "        titles = pd.Series([\"\"] * len(df))\n",
        "    texts = df[text_col].fillna(\"\")\n",
        "    concat = (titles + \" \" + texts).str.strip()\n",
        "    text_len = texts.str.len()\n",
        "    title_len = titles.str.len()\n",
        "    return concat, text_len, title_len\n",
        "\n",
        "# Build train features\n",
        "train_concat, train_text_len, train_title_len = build_concat_and_lengths(df)\n",
        "vectorizer_multi = build_tfidf(max_features=7000, ngram_range=(1, 2))\n",
        "X_train_concat = vectorizer_multi.fit_transform(train_concat)\n",
        "\n",
        "scaler_multi = StandardScaler(with_mean=False)\n",
        "num_train = np.vstack([train_text_len.values, train_title_len.values]).T\n",
        "num_train_scaled = csr_matrix(scaler_multi.fit_transform(num_train))\n",
        "X_train_multi = hstack([X_train_concat, num_train_scaled])\n",
        "\n",
        "y_train_multi = y_train_full\n",
        "\n",
        "# Build test features (fake-only and WELFake)\n",
        "fake_concat, fake_text_len, fake_title_len = build_concat_and_lengths(df_fake_test, text_col=\"text_cleaned\", title_col=\"title\" if \"title\" in df_fake_test.columns else \"title_cleaned\")\n",
        "welfake_concat, welfake_text_len, welfake_title_len = build_concat_and_lengths(df_welfake, text_col=\"text_cleaned\", title_col=\"title\" if \"title\" in df_welfake.columns else \"title_cleaned\")\n",
        "\n",
        "X_test_fake_concat = vectorizer_multi.transform(fake_concat)\n",
        "num_fake = np.vstack([fake_text_len.values, fake_title_len.values]).T\n",
        "num_fake_scaled = csr_matrix(scaler_multi.transform(num_fake))\n",
        "X_test_fake_multi = hstack([X_test_fake_concat, num_fake_scaled])\n",
        "\n",
        "a = vectorizer_multi.transform(welfake_concat)\n",
        "num_welfake = np.vstack([welfake_text_len.values, welfake_title_len.values]).T\n",
        "num_welfake_scaled = csr_matrix(scaler_multi.transform(num_welfake))\n",
        "X_test_welfake_multi = hstack([a, num_welfake_scaled])\n",
        "\n",
        "a = None  # free reference\n",
        "\n",
        "# Train & evaluate Logistic Regression (multi-feature)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Logistic Regression - Multi-feature (title+text+lengths) -> WELFake\")\n",
        "print(\"=\"*60)\n",
        "model_lr_multi = train_logreg(X_train_multi, y_train_multi)\n",
        "results_lr_welfake_multi = evaluate(model_lr_multi, X_test_welfake_multi, y_test_welfake, model_name=\"LogReg (multi-feature)\")\n",
        "\n",
        "# Train & evaluate Linear SVM (multi-feature)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Linear SVM - Multi-feature (title+text+lengths) -> WELFake\")\n",
        "print(\"=\"*60)\n",
        "model_svm_multi = train_svm(X_train_multi, y_train_multi)\n",
        "results_svm_welfake_multi = evaluate(model_svm_multi, X_test_welfake_multi, y_test_welfake, model_name=\"Linear SVM (multi-feature)\")\n",
        "\n",
        "# Fake-only test with multi-feature models\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Fake-only test set (all fake) - Multi-feature models\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fake_only_lr_multi = fake_only_report(model_lr_multi, X_test_fake_multi, \"LogReg (multi-feature, fake-only)\")\n",
        "fake_only_svm_multi = fake_only_report(model_svm_multi, X_test_fake_multi, \"Linear SVM (multi-feature, fake-only)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Advanced Models: Sentence Embeddings\n",
        "\n",
        "Train models using sentence embeddings as features, providing richer semantic representations than TF-IDF.\n",
        "\n",
        "**Note**: This section requires the `sentence-transformers` library. Uncomment and run if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ADVANCED MODELS: Sentence Embeddings\n",
            "============================================================\n",
            "Loading sentence-embedding model: all-MiniLM-L6-v2\n",
            "Using device for embeddings: mps\n",
            "Embedding model loaded successfully.\n",
            "\n",
            "Computing embeddings for full train and test sets...\n",
            "Encoding 44898 texts into embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56ab0e4831ee42178eb249c86bdd9127",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1404 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import embedding utilities\n",
        "spec = importlib.util.spec_from_file_location(\"embeddings_model\", project_root / \"src\" / \"05_embeddings_model.py\")\n",
        "embeddings_model = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(embeddings_model)\n",
        "sys.modules[\"embeddings_model\"] = embeddings_model\n",
        "from embeddings_model import build_embeddings, embed_text, train_embedding_classifier\n",
        "\n",
        "# Build sentence embedding model\n",
        "print(\"=\"*60)\n",
        "print(\"ADVANCED MODELS: Sentence Embeddings\")\n",
        "print(\"=\"*60)\n",
        "embedder = build_embeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Compute embeddings for full train and tests\n",
        "print(\"\\nComputing embeddings for full train and test sets...\")\n",
        "emb_train_full = embed_text(embedder, X_train_full)\n",
        "emb_test_fake_emb = embed_text(embedder, X_test_fake)\n",
        "emb_test_welfake_emb = embed_text(embedder, X_test_welfake)\n",
        "\n",
        "print(f\"Embedding dimension: {emb_train_full.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Embedding-based Classifier - Full Train -> WELFake\n",
            "============================================================\n",
            "Training Logistic Regression classifier on embeddings...\n",
            "  Training samples: 44898\n",
            "  Embedding dimension: 384\n",
            "  C (regularization): 1.0\n",
            "  max_iter: 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed.\n",
            "  Training accuracy on embeddings: 0.9617\n",
            "\n",
            "============================================================\n",
            "Evaluating Embedding Classifier (WELFake)\n",
            "============================================================\n",
            "Test set size: 10000 samples\n",
            "Class distribution: {np.int64(0): np.int64(4844), np.int64(1): np.int64(5156)}\n",
            "\n",
            "Metrics                   Value          \n",
            "----------------------------------------\n",
            "Accuracy                  0.8042\n",
            "Precision (macro)         0.8110\n",
            "Recall (macro)            0.8018\n",
            "F1-score (macro)          0.8021  <-- PRIMARY METRIC\n",
            "F1-score (weighted)       0.8027\n",
            "ROC-AUC                   0.8843  <-- Secondary metric\n",
            "PR-AUC (Avg Precision)    0.8752  <-- Secondary metric\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted Real  Predicted Fake \n",
            "Actual Real     3506            1338           \n",
            "Actual Fake     620             4536           \n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.85      0.72      0.78      4844\n",
            "        Fake       0.77      0.88      0.82      5156\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.81      0.80      0.80     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate embedding-based classifier -> WELFake\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Embedding-based Classifier - Full Train -> WELFake\")\n",
        "print(\"=\"*60)\n",
        "model_emb = train_embedding_classifier(emb_train_full, y_train_full)\n",
        "results_emb_welfake = evaluate(model_emb, emb_test_welfake_emb, y_test_welfake,\n",
        "                              model_name=\"Embedding Classifier (WELFake)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Fake-only test set (all fake) - Embedding model\n",
            "============================================================\n",
            "Embedding model: total=12999, false_negatives=3235, fake_recall=0.7511\n"
          ]
        }
      ],
      "source": [
        "# Fake-only test: false negatives / fake recall (embeddings)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Fake-only test set (all fake) - Embedding model\")\n",
        "print(\"=\"*60)\n",
        "emb_preds_fake = model_emb.predict(emb_test_fake_emb)\n",
        "total_fake = len(emb_preds_fake)\n",
        "# Fake class = 1; false negatives are predictions of 0 (real)\n",
        "fn_fake = np.sum(emb_preds_fake == 0)\n",
        "recall_fake_emb = 1 - fn_fake / total_fake if total_fake else float('nan')\n",
        "print(f\"Embedding model: total={total_fake}, false_negatives={fn_fake}, fake_recall={recall_fake_emb:.4f}\")\n",
        "fake_only_emb = {\"total\": int(total_fake), \"false_negatives\": int(fn_fake), \"fake_recall\": float(recall_fake_emb)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5b. Sentence Embeddings + Length Features\n",
        "\n",
        "Augment the sentence-embedding baseline by concatenating title+text and appending simple length features (text/title character counts) to see if these non-text signals help."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ADVANCED MODELS: Sentence Embeddings + Length Features\n",
            "============================================================\n",
            "Encoding 44898 texts into embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a723a5edae044b80848b349daf8d479a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1404 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (44898, 384)\n",
            "Encoding 12999 texts into embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8632ea0b23bf42b7ae818e074218764e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/407 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (12999, 384)\n",
            "Encoding 10000 texts into embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abd2f0fdcd4246a8bc5c4cf7423bf263",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (10000, 384)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ADVANCED MODELS: Sentence Embeddings + Length Features\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Reuse helper from TF-IDF multi-feature section to build concatenated texts and lengths\n",
        "# (build_concat_and_lengths must be defined in the earlier multi-feature cell)\n",
        "\n",
        "# Build train concatenated text and numeric features\n",
        "train_concat_emb, train_text_len_emb, train_title_len_emb = build_concat_and_lengths(df)\n",
        "train_concat_list = train_concat_emb.tolist()\n",
        "emb_train_concat = embed_text(embedder, train_concat_list)\n",
        "num_train_emb = np.vstack([train_text_len_emb.values, train_title_len_emb.values]).T\n",
        "num_scaler_emb = StandardScaler()\n",
        "num_train_emb_scaled = num_scaler_emb.fit_transform(num_train_emb)\n",
        "emb_train_multi = np.hstack([emb_train_concat, num_train_emb_scaled])\n",
        "\n",
        "y_train_emb_multi = y_train_full\n",
        "\n",
        "# Build test sets\n",
        "fake_concat_emb, fake_text_len_emb, fake_title_len_emb = build_concat_and_lengths(\n",
        "    df_fake_test, text_col=\"text_cleaned\", title_col=\"title\" if \"title\" in df_fake_test.columns else \"title_cleaned\"\n",
        ")\n",
        "fake_concat_list = fake_concat_emb.tolist()\n",
        "\n",
        "welfake_concat_emb, welfake_text_len_emb, welfake_title_len_emb = build_concat_and_lengths(\n",
        "    df_welfake, text_col=\"text_cleaned\", title_col=\"title\" if \"title\" in df_welfake.columns else \"title_cleaned\"\n",
        ")\n",
        "welfake_concat_list = welfake_concat_emb.tolist()\n",
        "\n",
        "emb_test_fake_concat = embed_text(embedder, fake_concat_list)\n",
        "num_fake_emb = np.vstack([fake_text_len_emb.values, fake_title_len_emb.values]).T\n",
        "num_fake_emb_scaled = num_scaler_emb.transform(num_fake_emb)\n",
        "emb_test_fake_multi = np.hstack([emb_test_fake_concat, num_fake_emb_scaled])\n",
        "\n",
        "emb_test_welfake_concat = embed_text(embedder, welfake_concat_list)\n",
        "num_welfake_emb = np.vstack([welfake_text_len_emb.values, welfake_title_len_emb.values]).T\n",
        "num_welfake_emb_scaled = num_scaler_emb.transform(num_welfake_emb)\n",
        "emb_test_welfake_multi = np.hstack([emb_test_welfake_concat, num_welfake_emb_scaled])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Embedding + Lengths Classifier - Full Train -> WELFake\n",
            "============================================================\n",
            "Training Logistic Regression classifier on embeddings...\n",
            "  Training samples: 44898\n",
            "  Embedding dimension: 386\n",
            "  C (regularization): 1.0\n",
            "  max_iter: 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed.\n",
            "  Training accuracy on embeddings: 0.9674\n",
            "\n",
            "============================================================\n",
            "Evaluating Embedding + Lengths (WELFake)\n",
            "============================================================\n",
            "Test set size: 10000 samples\n",
            "Class distribution: {np.int64(0): np.int64(4844), np.int64(1): np.int64(5156)}\n",
            "\n",
            "Metrics                   Value          \n",
            "----------------------------------------\n",
            "Accuracy                  0.7932\n",
            "Precision (macro)         0.7943\n",
            "Recall (macro)            0.7920\n",
            "F1-score (macro)          0.7924  <-- PRIMARY METRIC\n",
            "F1-score (weighted)       0.7928\n",
            "ROC-AUC                   0.8665  <-- Secondary metric\n",
            "PR-AUC (Avg Precision)    0.8791  <-- Secondary metric\n",
            "\n",
            "Confusion Matrix:\n",
            "                Predicted Real  Predicted Fake \n",
            "Actual Real     3658            1186           \n",
            "Actual Fake     882             4274           \n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.81      0.76      0.78      4844\n",
            "        Fake       0.78      0.83      0.81      5156\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate Logistic Regression (embeddings + lengths)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Embedding + Lengths Classifier - Full Train -> WELFake\")\n",
        "print(\"=\"*60)\n",
        "model_emb_multi = train_embedding_classifier(emb_train_multi, y_train_emb_multi)\n",
        "results_emb_welfake_multi = evaluate(model_emb_multi, emb_test_welfake_multi, y_test_welfake,\n",
        "                                    model_name=\"Embedding + Lengths (WELFake)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Fake-only test set (all fake) - Embedding + lengths model\n",
            "============================================================\n",
            "Embedding+lengths model: total=12999, false_negatives=5379, fake_recall=0.5862\n"
          ]
        }
      ],
      "source": [
        "# Fake-only test: false negatives / fake recall (embeddings + lengths)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Fake-only test set (all fake) - Embedding + lengths model\")\n",
        "print(\"=\"*60)\n",
        "emb_preds_fake_multi = model_emb_multi.predict(emb_test_fake_multi)\n",
        "total_fake_multi = len(emb_preds_fake_multi)\n",
        "fn_fake_multi = np.sum(emb_preds_fake_multi == 0)\n",
        "recall_fake_emb_multi = 1 - fn_fake_multi / total_fake_multi if total_fake_multi else float('nan')\n",
        "print(f\"Embedding+lengths model: total={total_fake_multi}, false_negatives={fn_fake_multi}, fake_recall={recall_fake_emb_multi:.4f}\")\n",
        "fake_only_emb_multi = {\"total\": int(total_fake_multi), \"false_negatives\": int(fn_fake_multi), \"fake_recall\": float(recall_fake_emb_multi)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results Summary\n",
        "\n",
        "Compare models on WELFake (mixed labeled) and report fake-only recall on `data/test/fake.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Model Performance Comparison:\n",
            "                        Model  WELFake - Macro-F1  WELFake - ROC-AUC  WELFake - PR-AUC  Fake-only recall\n",
            "              LogReg (TF-IDF)            0.830949           0.904819          0.878144          0.936457\n",
            "          Linear SVM (TF-IDF)            0.828783           0.903293          0.880313          0.947304\n",
            "    LogReg (TF-IDF + lengths)            0.808537           0.899661          0.897192          0.724594\n",
            "Linear SVM (TF-IDF + lengths)            0.819348           0.914173          0.909507          0.835141\n",
            "        Embedding (text only)            0.802100           0.884306          0.875243          0.751135\n",
            "          Embedding + lengths            0.792412           0.866485          0.879129          0.586199\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Safe helper in case some runs are skipped\n",
        "\n",
        "def safe(d, key):\n",
        "    return None if d is None else d.get(key)\n",
        "\n",
        "results_summary = pd.DataFrame({\n",
        "    \"Model\": [\n",
        "        \"LogReg (TF-IDF)\",\n",
        "        \"Linear SVM (TF-IDF)\",\n",
        "        \"LogReg (TF-IDF + lengths)\",\n",
        "        \"Linear SVM (TF-IDF + lengths)\",\n",
        "        \"Embedding (text only)\",\n",
        "        \"Embedding + lengths\",\n",
        "    ],\n",
        "    \"WELFake - Macro-F1\": [\n",
        "        safe(results_lr_welfake, \"f1_macro\"),\n",
        "        safe(results_svm_welfake, \"f1_macro\"),\n",
        "        safe(results_lr_welfake_multi, \"f1_macro\"),\n",
        "        safe(results_svm_welfake_multi, \"f1_macro\"),\n",
        "        safe(results_emb_welfake, \"f1_macro\"),\n",
        "        safe(results_emb_welfake_multi, \"f1_macro\"),\n",
        "    ],\n",
        "    \"WELFake - ROC-AUC\": [\n",
        "        safe(results_lr_welfake, \"roc_auc\"),\n",
        "        safe(results_svm_welfake, \"roc_auc\"),\n",
        "        safe(results_lr_welfake_multi, \"roc_auc\"),\n",
        "        safe(results_svm_welfake_multi, \"roc_auc\"),\n",
        "        safe(results_emb_welfake, \"roc_auc\"),\n",
        "        safe(results_emb_welfake_multi, \"roc_auc\"),\n",
        "    ],\n",
        "    \"WELFake - PR-AUC\": [\n",
        "        safe(results_lr_welfake, \"pr_auc\"),\n",
        "        safe(results_svm_welfake, \"pr_auc\"),\n",
        "        safe(results_lr_welfake_multi, \"pr_auc\"),\n",
        "        safe(results_svm_welfake_multi, \"pr_auc\"),\n",
        "        safe(results_emb_welfake, \"pr_auc\"),\n",
        "        safe(results_emb_welfake_multi, \"pr_auc\"),\n",
        "    ],\n",
        "    \"Fake-only recall\": [\n",
        "        safe(fake_only_lr, \"fake_recall\"),\n",
        "        safe(fake_only_svm, \"fake_recall\"),\n",
        "        safe(fake_only_lr_multi, \"fake_recall\"),\n",
        "        safe(fake_only_svm_multi, \"fake_recall\"),\n",
        "        safe(fake_only_emb, \"fake_recall\"),\n",
        "        safe(fake_only_emb_multi, \"fake_recall\"),\n",
        "    ],\n",
        "})\n",
        "\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(results_summary.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusions and Discussion\n",
        "\n",
        "### Key Findings\n",
        "- **TF-IDF remains strongest** on WELFake 10k: LogReg macro-F1 0.831 (ROC-AUC 0.905); Linear SVM macro-F1 0.829 (ROC-AUC 0.903).\n",
        "- **Length features did not help**: Adding title/text lengths dropped macro-F1 (0.8080.819) and fake-only recall (down to 0.720.84).\n",
        "- **Embeddings trail TF-IDF**: Text-only embeddings macro-F1 0.802 (ROC-AUC 0.884); adding lengths hurt further (macro-F1 0.792).\n",
        "- **Fake-only recall best for TF-IDF SVM**: Recall 0.947; embedding+lengths greatly increased false negatives.\n",
        "\n",
        "### Interpretation\n",
        "- Simple length cues are weak signals here and can harm recall; more discriminative metadata/structure is needed.\n",
        "- Cross-dataset robustness is modest (macro-F1 0.790.83) despite decent ROC-AUC, indicating persistent domain/style mismatch.\n",
        "- TF-IDF still outperforms sentence embeddings under this setup; embeddings + naive numeric features are not closing the gap.\n",
        "\n",
        "### Next Steps\n",
        "- Explore richer features: URL/domain tokens, punctuation/ratio features, and explicit title/body weighting instead of raw lengths.\n",
        "- Consider domain adaptation or light fine-tuning on a WELFake-like validation split; calibrate decision thresholds for recall/precision trade-offs.\n",
        "- Transformers remain excluded for runtime; revisit with tighter configs (shorter max_length, partial epochs) if compute allows.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
