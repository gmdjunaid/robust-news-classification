{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust News Classification: Main Experiments\n",
    "\n",
    "This notebook ties together all components of the robust news classification project for the current flow (train on full ISOT, test on held-out files).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Data Loading & Preprocessing**: Load ISOT training data and clean text\n",
    "2. **Training**: Train on the full ISOT training set (Fake + True)\n",
    "3. **Baseline Models**: TF-IDF + LogReg/SVM\n",
    "4. **Advanced Models**: Sentence embeddings (MiniLM) and Transformer (DistilBERT)\n",
    "5. **Evaluation**:\n",
    "   - Fake-only test (`data/test/fake.csv`): false negatives / fake recall\n",
    "   - Mixed labeled test (`data/test/WELFake_Dataset_sample_10000.csv`): Macro-F1, ROC-AUC, PR-AUC, confusion matrix\n",
    "6. **Cross-Dataset Transfer**: WELFake evaluation covers the external test without fine-tuning\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "- Train on full labeled ISOT data (text only)\n",
    "- Check false negatives on fake-only held-out data\n",
    "- Measure balanced metrics on a mixed external set (WELFake)\n",
    "- Compare TF-IDF baselines with embedding and transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import all necessary modules from the `src/` directory and configure settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "Project root: /Users/reuben/robust-news-classification/robust-news-classification\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path for imports\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Import using importlib for files with numeric prefixes\n",
    "import importlib.util\n",
    "\n",
    "# Import preprocessing utilities\n",
    "spec = importlib.util.spec_from_file_location(\"preprocessing\", project_root / \"src\" / \"01_preprocessing.py\")\n",
    "preprocessing = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(preprocessing)\n",
    "sys.modules[\"preprocessing\"] = preprocessing\n",
    "from preprocessing import load_isot, apply_cleaning, clean_text\n",
    "\n",
    "# Import baseline models\n",
    "spec = importlib.util.spec_from_file_location(\"baseline_models\", project_root / \"src\" / \"03_baseline_models.py\")\n",
    "baseline_models = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(baseline_models)\n",
    "sys.modules[\"baseline_models\"] = baseline_models\n",
    "from baseline_models import build_tfidf, train_logreg, train_svm\n",
    "\n",
    "# Import evaluation\n",
    "spec = importlib.util.spec_from_file_location(\"baseline_eval\", project_root / \"src\" / \"04_baseline_eval.py\")\n",
    "baseline_eval = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(baseline_eval)\n",
    "sys.modules[\"baseline_eval\"] = baseline_eval\n",
    "from baseline_eval import evaluate\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "Load the ISOT dataset (Fake and True news) and apply text cleaning to remove noise and standardize formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ISOT dataset...\n",
      "Loading fake news from ../data/training/Fake.csv...\n",
      "Loading real news from ../data/training/True.csv...\n",
      "Loaded 23481 fake articles and 21417 real articles\n",
      "Total: 44898 articles\n",
      "\n",
      "Dataset shape: (44898, 6)\n",
      "Columns: ['title', 'text', 'subject', 'date', 'label', 'source_file']\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "1    23481\n",
      "0    21417\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Subject distribution:\n",
      "subject\n",
      "politicsNews       11272\n",
      "worldnews          10145\n",
      "News                9050\n",
      "politics            6841\n",
      "left-news           4459\n",
      "Government News     1570\n",
      "US_News              783\n",
      "Middle-east          778\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "Applying text cleaning...\n",
      "Applied text cleaning to column 'text'\n",
      "Created new column 'text_cleaned' with cleaned text\n",
      "Applied text cleaning to column 'title'\n",
      "Created new column 'title_cleaned' with cleaned text\n",
      "\n",
      "Sample cleaned text (first 200 chars):\n",
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and the very dishonest fake news media. The former reali\n"
     ]
    }
   ],
   "source": [
    "# Load ISOT dataset\n",
    "print(\"Loading ISOT dataset...\")\n",
    "df = load_isot(\n",
    "    fake_path='../data/training/Fake.csv',\n",
    "    real_path='../data/training/True.csv'\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nSubject distribution:\")\n",
    "print(df['subject'].value_counts())\n",
    "\n",
    "# Apply text cleaning\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Applying text cleaning...\")\n",
    "df = apply_cleaning(df, text_column='text')\n",
    "df = apply_cleaning(df, text_column='title')\n",
    "\n",
    "print(f\"\\nSample cleaned text (first 200 chars):\")\n",
    "print(df['text_cleaned'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Setup\n",
    "\n",
    "Train on the full ISOT training set (Fake + True). Evaluate on two held-out files:\n",
    "- `data/test/fake.csv` (all fake) to measure false negatives (fake recall)\n",
    "- `data/test/WELFake_Dataset_sample_10000.csv` (mixed, labeled) for full metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Preparing train and held-out test sets\n",
      "============================================================\n",
      "\n",
      "Loading fake-only test set (all fake)...\n",
      "\n",
      "Loading WELFake test set (mixed labeled)...\n",
      "Train size: 44898\n",
      "Fake-only test size: 12999\n",
      "WELFake test size: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Preparing train and held-out test sets\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train on full ISOT training set\n",
    "X_train_full = df['text_cleaned'].tolist()\n",
    "y_train_full = df['label'].values\n",
    "\n",
    "# Fake-only test set: measure false negatives / fake recall\n",
    "print(\"\\nLoading fake-only test set (all fake)...\")\n",
    "df_fake_test = pd.read_csv('../data/test/fake.csv')\n",
    "df_fake_test['text_cleaned'] = df_fake_test['text'].apply(clean_text)\n",
    "X_test_fake = df_fake_test['text_cleaned'].tolist()\n",
    "# Fake class = 1 (original convention)\n",
    "y_test_fake = np.ones(len(df_fake_test), dtype=int)\n",
    "\n",
    "# WELFake mixed test set: full metrics\n",
    "print(\"\\nLoading WELFake test set (mixed labeled)...\")\n",
    "df_welfake = pd.read_csv('../data/test/WELFake_Dataset_sample_10000.csv')\n",
    "# WELFake labels are actually 0=real, 1=fake; this matches our convention, so no mapping needed\n",
    "# If you find labels are reversed, flip with {0:1, 1:0}\n",
    "df_welfake['text_cleaned'] = df_welfake['text'].apply(clean_text)\n",
    "X_test_welfake = df_welfake['text_cleaned'].tolist()\n",
    "y_test_welfake = df_welfake['label'].values\n",
    "\n",
    "print(f\"Train size: {len(X_train_full)}\")\n",
    "print(f\"Fake-only test size: {len(X_test_fake)}\")\n",
    "print(f\"WELFake test size: {len(X_test_welfake)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Models: TF-IDF + Linear Classifiers\n",
    "\n",
    "Train interpretable baseline models using TF-IDF features with Logistic Regression and Linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE MODELS: TF-IDF + Linear Classifiers\n",
      "============================================================\n",
      "Created TF-IDF vectorizer with:\n",
      "  max_features: 5000\n",
      "  min_df: 2\n",
      "  max_df: 0.95\n",
      "  ngram_range: (1, 2)\n",
      "  stop_words: english\n",
      "\n",
      "TF-IDF feature matrix shape: (44898, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Build TF-IDF vectorizer\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE MODELS: TF-IDF + Linear Classifiers\")\n",
    "print(\"=\"*60)\n",
    "vectorizer = build_tfidf(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# Transform text data (fit once on full training set)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_full)\n",
    "X_test_fake_tfidf = vectorizer.transform(X_test_fake)\n",
    "X_test_welfake_tfidf = vectorizer.transform(X_test_welfake)\n",
    "\n",
    "print(f\"\\nTF-IDF feature matrix shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Logistic Regression - Full Train -> WELFake\n",
      "============================================================\n",
      "Training Logistic Regression classifier...\n",
      "  Training samples: 44898\n",
      "  C (regularization): 1.0\n",
      "  max_iter: 1000\n",
      "  solver: lbfgs\n",
      "Training completed.\n",
      "  Training accuracy: 0.9925\n",
      "\n",
      "============================================================\n",
      "Evaluating Logistic Regression (WELFake)\n",
      "============================================================\n",
      "Test set size: 1000 samples\n",
      "Class distribution: {np.int64(0): np.int64(466), np.int64(1): np.int64(534)}\n",
      "\n",
      "Metrics                   Value          \n",
      "----------------------------------------\n",
      "Accuracy                  0.8450\n",
      "Precision (macro)         0.8796\n",
      "Recall (macro)            0.8346\n",
      "F1-score (macro)          0.8379  <-- PRIMARY METRIC\n",
      "F1-score (weighted)       0.8402\n",
      "ROC-AUC                   0.9047  <-- Secondary metric\n",
      "PR-AUC (Avg Precision)    0.8920  <-- Secondary metric\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Real  Predicted Fake \n",
      "Actual Real     318             148            \n",
      "Actual Fake     7               527            \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.98      0.68      0.80       466\n",
      "        Fake       0.78      0.99      0.87       534\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.88      0.83      0.84      1000\n",
      "weighted avg       0.87      0.84      0.84      1000\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Logistic Regression on full train -> WELFake\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Logistic Regression - Full Train -> WELFake\")\n",
    "print(\"=\"*60)\n",
    "model_lr = train_logreg(X_train_tfidf, y_train_full)\n",
    "results_lr_welfake = evaluate(model_lr, X_test_welfake_tfidf, y_test_welfake, \n",
    "                             model_name=\"Logistic Regression (WELFake)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Linear SVM - Full Train -> WELFake\n",
      "============================================================\n",
      "Training Linear SVM classifier...\n",
      "  Training samples: 44898\n",
      "  C (regularization): 1.0\n",
      "  max_iter: 1000\n",
      "  dual: False\n",
      "Training completed.\n",
      "  Training accuracy: 0.9990\n",
      "\n",
      "============================================================\n",
      "Evaluating Linear SVM (WELFake)\n",
      "============================================================\n",
      "Test set size: 1000 samples\n",
      "Class distribution: {np.int64(0): np.int64(466), np.int64(1): np.int64(534)}\n",
      "\n",
      "Metrics                   Value          \n",
      "----------------------------------------\n",
      "Accuracy                  0.8360\n",
      "Precision (macro)         0.8753\n",
      "Recall (macro)            0.8249\n",
      "F1-score (macro)          0.8277  <-- PRIMARY METRIC\n",
      "F1-score (weighted)       0.8302\n",
      "ROC-AUC                   0.9053  <-- Secondary metric\n",
      "PR-AUC (Avg Precision)    0.8927  <-- Secondary metric\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Real  Predicted Fake \n",
      "Actual Real     308             158            \n",
      "Actual Fake     6               528            \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.98      0.66      0.79       466\n",
      "        Fake       0.77      0.99      0.87       534\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.88      0.82      0.83      1000\n",
      "weighted avg       0.87      0.84      0.83      1000\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Linear SVM on full train -> WELFake\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Linear SVM - Full Train -> WELFake\")\n",
    "print(\"=\"*60)\n",
    "model_svm = train_svm(X_train_tfidf, y_train_full)\n",
    "results_svm_welfake = evaluate(model_svm, X_test_welfake_tfidf, y_test_welfake,\n",
    "                              model_name=\"Linear SVM (WELFake)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Fake-only test set (all fake) - TF-IDF models\n",
      "============================================================\n",
      "LogReg (fake-only): total=12999, false_negatives=826, fake_recall=0.9365\n",
      "Linear SVM (fake-only): total=12999, false_negatives=685, fake_recall=0.9473\n"
     ]
    }
   ],
   "source": [
    "# Fake-only test: false negatives / fake recall (TF-IDF models)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Fake-only test set (all fake) - TF-IDF models\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def fake_only_report(model, X_fake, model_name):\n",
    "    preds = model.predict(X_fake)\n",
    "    total = len(preds)\n",
    "    # Fake class = 1; false negatives are predictions of 0 (real)\n",
    "    fn = np.sum(preds == 0)\n",
    "    recall_fake = 1 - fn / total if total else float('nan')\n",
    "    print(f\"{model_name}: total={total}, false_negatives={fn}, fake_recall={recall_fake:.4f}\")\n",
    "    return {\"total\": int(total), \"false_negatives\": int(fn), \"fake_recall\": float(recall_fake)}\n",
    "\n",
    "fake_only_lr = fake_only_report(model_lr, X_test_fake_tfidf, \"LogReg (fake-only)\")\n",
    "fake_only_svm = fake_only_report(model_svm, X_test_fake_tfidf, \"Linear SVM (fake-only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Models: Sentence Embeddings\n",
    "\n",
    "Train models using sentence embeddings as features, providing richer semantic representations than TF-IDF.\n",
    "\n",
    "**Note**: This section requires the `sentence-transformers` library. Uncomment and run if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADVANCED MODELS: Sentence Embeddings\n",
      "============================================================\n",
      "Loading sentence-embedding model: all-MiniLM-L6-v2\n",
      "Embedding model loaded successfully.\n",
      "\n",
      "Computing embeddings for full train and test sets...\n",
      "Encoding 44898 texts into embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2516682966b140a18c4c939447b77443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (44898, 384)\n",
      "Encoding 12999 texts into embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239b57c181e34f0cb0d508d90c621ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (12999, 384)\n",
      "Encoding 1000 texts into embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cefc19fc734454a818517d87d226f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1000, 384)\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Import embedding utilities\n",
    "spec = importlib.util.spec_from_file_location(\"embeddings_model\", project_root / \"src\" / \"05_embeddings_model.py\")\n",
    "embeddings_model = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(embeddings_model)\n",
    "sys.modules[\"embeddings_model\"] = embeddings_model\n",
    "from embeddings_model import build_embeddings, embed_text, train_embedding_classifier\n",
    "\n",
    "# Build sentence embedding model\n",
    "print(\"=\"*60)\n",
    "print(\"ADVANCED MODELS: Sentence Embeddings\")\n",
    "print(\"=\"*60)\n",
    "embedder = build_embeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embeddings for full train and tests\n",
    "print(\"\\nComputing embeddings for full train and test sets...\")\n",
    "emb_train_full = embed_text(embedder, X_train_full)\n",
    "emb_test_fake_emb = embed_text(embedder, X_test_fake)\n",
    "emb_test_welfake_emb = embed_text(embedder, X_test_welfake)\n",
    "\n",
    "print(f\"Embedding dimension: {emb_train_full.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Embedding-based Classifier - Full Train -> WELFake\n",
      "============================================================\n",
      "Training Logistic Regression classifier on embeddings...\n",
      "  Training samples: 44898\n",
      "  Embedding dimension: 384\n",
      "  C (regularization): 1.0\n",
      "  max_iter: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "  Training accuracy on embeddings: 0.9617\n",
      "\n",
      "============================================================\n",
      "Evaluating Embedding Classifier (WELFake)\n",
      "============================================================\n",
      "Test set size: 1000 samples\n",
      "Class distribution: {np.int64(0): np.int64(466), np.int64(1): np.int64(534)}\n",
      "\n",
      "Metrics                   Value          \n",
      "----------------------------------------\n",
      "Accuracy                  0.8120\n",
      "Precision (macro)         0.8200\n",
      "Recall (macro)            0.8059\n",
      "F1-score (macro)          0.8080  <-- PRIMARY METRIC\n",
      "F1-score (weighted)       0.8099\n",
      "ROC-AUC                   0.8913  <-- Secondary metric\n",
      "PR-AUC (Avg Precision)    0.8896  <-- Secondary metric\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Real  Predicted Fake \n",
      "Actual Real     334             132            \n",
      "Actual Fake     56              478            \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.86      0.72      0.78       466\n",
      "        Fake       0.78      0.90      0.84       534\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate embedding-based classifier -> WELFake\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Embedding-based Classifier - Full Train -> WELFake\")\n",
    "print(\"=\"*60)\n",
    "model_emb = train_embedding_classifier(emb_train_full, y_train_full)\n",
    "results_emb_welfake = evaluate(model_emb, emb_test_welfake_emb, y_test_welfake,\n",
    "                              model_name=\"Embedding Classifier (WELFake)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Fake-only test set (all fake) - Embedding model\n",
      "============================================================\n",
      "Embedding model: total=12999, false_negatives=3235, fake_recall=0.7511\n"
     ]
    }
   ],
   "source": [
    "# Fake-only test: false negatives / fake recall (embeddings)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Fake-only test set (all fake) - Embedding model\")\n",
    "print(\"=\"*60)\n",
    "emb_preds_fake = model_emb.predict(emb_test_fake_emb)\n",
    "total_fake = len(emb_preds_fake)\n",
    "# Fake class = 1; false negatives are predictions of 0 (real)\n",
    "fn_fake = np.sum(emb_preds_fake == 0)\n",
    "recall_fake_emb = 1 - fn_fake / total_fake if total_fake else float('nan')\n",
    "print(f\"Embedding model: total={total_fake}, false_negatives={fn_fake}, fake_recall={recall_fake_emb:.4f}\")\n",
    "fake_only_emb = {\"total\": int(total_fake), \"false_negatives\": int(fn_fake), \"fake_recall\": float(recall_fake_emb)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b. Advanced Models: Transformer (DistilBERT)\n",
    "\n",
    "Fine-tune a DistilBERT transformer on the ISOT training data and evaluate on WELFake.\n",
    "\n",
    "**Note**: This section requires `transformers` and `torch`. Training takes ~10-20 minutes on CPU, faster on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADVANCED MODELS: Transformer (DistilBERT)\n",
      "============================================================\n",
      "Loading transformer model 'distilbert-base-uncased' for sequence classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import transformer utilities\n",
    "spec = importlib.util.spec_from_file_location(\"transformer_model\", project_root / \"src\" / \"06_transformer_model.py\")\n",
    "transformer_model = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(transformer_model)\n",
    "sys.modules[\"transformer_model\"] = transformer_model\n",
    "from transformer_model import build_transformer, train_transformer, TransformerSklearnWrapper\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ADVANCED MODELS: Transformer (DistilBERT)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Build transformer model and tokenizer\n",
    "model_transformer, tokenizer = build_transformer(model_name=\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Fine-tuning DistilBERT on ISOT data...\n",
      "============================================================\n",
      "Preparing dataset for transformer fine-tuning...\n",
      "Configuring TrainingArguments...\n",
      "Initializing Trainer and starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1830' max='2807' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1830/2807 36:01 < 19:14, 0.85 it/s, Epoch 0.65/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine-tune transformer on ISOT training data\n",
    "# Note: This can take 10-20+ minutes on CPU. Reduce num_train_epochs or use GPU for faster training.\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Fine-tuning DistilBERT on ISOT data...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_transformer = train_transformer(\n",
    "    model=model_transformer,\n",
    "    tokenizer=tokenizer,\n",
    "    train_texts=X_train_full,\n",
    "    train_labels=y_train_full,\n",
    "    output_dir=str(project_root / \"models\" / \"distilbert_isot\"),\n",
    "    num_train_epochs=1,  # Start with 1 epoch for faster iteration; increase to 3 for better results\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap transformer for sklearn-compatible evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Transformer Evaluation - Full Train -> WELFake\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "transformer_wrapper = TransformerSklearnWrapper(\n",
    "    model=model_transformer,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256,\n",
    ")\n",
    "\n",
    "# Evaluate on WELFake (pass raw text - wrapper handles tokenization)\n",
    "results_transformer_welfake = evaluate(\n",
    "    transformer_wrapper, \n",
    "    X_test_welfake,  # Raw text, not embeddings\n",
    "    y_test_welfake, \n",
    "    model_name=\"DistilBERT Transformer (WELFake)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake-only test: false negatives / fake recall (transformer)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Fake-only test set (all fake) - Transformer model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Note: This may take a few minutes due to the large test set (12999 samples)\n",
    "# Process in batches to avoid memory issues\n",
    "batch_size = 64\n",
    "transformer_preds_fake = []\n",
    "\n",
    "print(f\"Running inference on {len(X_test_fake)} samples in batches of {batch_size}...\")\n",
    "for i in range(0, len(X_test_fake), batch_size):\n",
    "    batch = X_test_fake[i:i+batch_size]\n",
    "    preds = transformer_wrapper.predict(batch)\n",
    "    transformer_preds_fake.extend(preds)\n",
    "    if (i // batch_size + 1) % 50 == 0:\n",
    "        print(f\"  Processed {min(i+batch_size, len(X_test_fake))}/{len(X_test_fake)} samples...\")\n",
    "\n",
    "transformer_preds_fake = np.array(transformer_preds_fake)\n",
    "total_fake_transformer = len(transformer_preds_fake)\n",
    "# Fake class = 1; false negatives are predictions of 0 (real)\n",
    "fn_fake_transformer = np.sum(transformer_preds_fake == 0)\n",
    "recall_fake_transformer = 1 - fn_fake_transformer / total_fake_transformer if total_fake_transformer else float('nan')\n",
    "\n",
    "print(f\"Transformer: total={total_fake_transformer}, false_negatives={fn_fake_transformer}, fake_recall={recall_fake_transformer:.4f}\")\n",
    "fake_only_transformer = {\"total\": int(total_fake_transformer), \"false_negatives\": int(fn_fake_transformer), \"fake_recall\": float(recall_fake_transformer)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary\n",
    "\n",
    "Compare models on WELFake (mixed labeled) and report fake-only recall on `data/test/fake.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results summary\n",
    "print(\"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Logistic Regression (TF-IDF)',\n",
    "        'Linear SVM (TF-IDF)',\n",
    "        'Embedding Classifier',\n",
    "        'DistilBERT Transformer',\n",
    "    ],\n",
    "    'WELFake - Macro-F1': [\n",
    "        results_lr_welfake['f1_macro'],\n",
    "        results_svm_welfake['f1_macro'],\n",
    "        results_emb_welfake['f1_macro'] if 'results_emb_welfake' in locals() else None,\n",
    "        results_transformer_welfake['f1_macro'] if 'results_transformer_welfake' in locals() else None,\n",
    "    ],\n",
    "    'WELFake - ROC-AUC': [\n",
    "        results_lr_welfake['roc_auc'],\n",
    "        results_svm_welfake['roc_auc'],\n",
    "        results_emb_welfake['roc_auc'] if 'results_emb_welfake' in locals() else None,\n",
    "        results_transformer_welfake['roc_auc'] if 'results_transformer_welfake' in locals() else None,\n",
    "    ],\n",
    "    'WELFake - PR-AUC': [\n",
    "        results_lr_welfake['pr_auc'],\n",
    "        results_svm_welfake['pr_auc'],\n",
    "        results_emb_welfake['pr_auc'] if 'results_emb_welfake' in locals() else None,\n",
    "        results_transformer_welfake['pr_auc'] if 'results_transformer_welfake' in locals() else None,\n",
    "    ],\n",
    "    'Fake-only recall': [\n",
    "        fake_only_lr['fake_recall'],\n",
    "        fake_only_svm['fake_recall'],\n",
    "        fake_only_emb['fake_recall'] if 'fake_only_emb' in locals() else None,\n",
    "        fake_only_transformer['fake_recall'] if 'fake_only_transformer' in locals() else None,\n",
    "    ],\n",
    "})\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Dataset Transfer Evaluation\n",
    "\n",
    "Handled above by running the ISOT-trained models on WELFake (zero-shot, no fine-tuning). No additional code needed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Reference) Cross-dataset transfer summary: see WELFake results above; no further actions here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions and Discussion\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Performance**: Compare baseline (TF-IDF) vs. advanced (embeddings, transformers) approaches\n",
    "2. **Robustness**: Assess performance drop from random splits to topic-holdout splits\n",
    "3. **Generalization**: Evaluate cross-dataset transfer performance on WELFake\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Macro-F1** serves as the primary metric to balance performance across classes\n",
    "- **Topic-holdout splits** reveal whether models rely on topic-specific shortcuts\n",
    "- **Cross-dataset evaluation** tests real-world applicability beyond ISOT\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Fine-tune hyperparameters for optimal performance\n",
    "- Analyze failure cases and model interpretability\n",
    "- Expand cross-dataset evaluation to additional external datasets\n",
    "- Add transformer model evaluation (requires additional setup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
